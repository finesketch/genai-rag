{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54329b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2ce004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "404cf908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_params_dict(\n",
    "    prompt: str, \n",
    "    temperature: float = 1, \n",
    "    role = 'user',\n",
    "    top_p: float = 1,\n",
    "    max_tokens: int = 500,\n",
    "    model: str = \"meta-llama/Llama-3.2-3B-Instruct-Turbo\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Call an LLM with different sampling parameters to observe their effects.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The text prompt to send to the model\n",
    "        temperature: Controls randomness (lower = more deterministic)\n",
    "        top_p: Controls diversity via nucleus sampling\n",
    "        max_tokens: Maximum number of tokens to generate\n",
    "        model: The model to use\n",
    "        \n",
    "    Returns:\n",
    "        The LLM response\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the dictionary with the necessary parameters\n",
    "    kwargs = {\"prompt\": prompt, 'role':role, \"temperature\": temperature, \"top_p\": top_p, \"max_tokens\": max_tokens, 'model': model} \n",
    "\n",
    "\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b6fc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_single_input(prompt: str, \n",
    "                               role: str = 'user', \n",
    "                               top_p: float = 1, \n",
    "                               temperature: float = 1,\n",
    "                               max_tokens: int = 500,\n",
    "                               model: str =\"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
    "                               together_api_key = None,\n",
    "                              **kwargs):\n",
    "    \n",
    "    if top_p is None:\n",
    "        top_p = 1\n",
    "    if temperature is None:\n",
    "        temperature = 1\n",
    "\n",
    "    payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [{'role': role, 'content': prompt}],\n",
    "            \"top_p\": top_p,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            **kwargs\n",
    "                  }\n",
    "    if (not together_api_key) and ('TOGETHER_API_KEY' not in os.environ):\n",
    "        url = os.path.join('https://proxy.dlai.link/coursera_proxy/together', 'v1/chat/completions')   \n",
    "        response = requests.post(url, json = payload, verify=False)\n",
    "        if not response.ok:\n",
    "            raise Exception(f\"Error while calling LLM: f{response.text}\")\n",
    "        try:\n",
    "            json_dict = json.loads(response.text)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to get correct output from LLM call.\\nException: {e}\\nResponse: {response.text}\")\n",
    "    else:\n",
    "        if together_api_key is None:\n",
    "            together_api_key = os.environ['TOGETHER_API_KEY']\n",
    "        client = Together(api_key =  together_api_key)\n",
    "        json_dict = client.chat.completions.create(**payload).model_dump()\n",
    "        json_dict['choices'][-1]['message']['role'] = json_dict['choices'][-1]['message']['role'].name.lower()\n",
    "    try:\n",
    "        output_dict = {'role': json_dict['choices'][-1]['message']['role'], 'content': json_dict['choices'][-1]['message']['content']}\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to get correct output dict. Please try again. Error: {e}\")\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea38c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_multiple_input(messages: List[Dict], \n",
    "                               top_p: float = 1, \n",
    "                               temperature: float = 1,\n",
    "                               max_tokens: int = 500,\n",
    "                               model: str =\"meta-llama/Llama-3.2-3B-Instruct-Turbo\", \n",
    "                                together_api_key = None,\n",
    "                                **kwargs):\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"top_p\": top_p,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        **kwargs\n",
    "              }\n",
    "    if (not together_api_key) and ('TOGETHER_API_KEY' not in os.environ):\n",
    "        url = os.path.join('https://proxy.dlai.link/coursera_proxy/together', 'v1/chat/completions')   \n",
    "        response = requests.post(url, json = payload, verify=False)\n",
    "        if not response.ok:\n",
    "            raise Exception(f\"Error while calling LLM: f{response.text}\")\n",
    "        try:\n",
    "            json_dict = json.loads(response.text)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to get correct output from LLM call.\\nException: {e}\\nResponse: {response.text}\")\n",
    "    else:\n",
    "        if together_api_key is None:\n",
    "            together_api_key = os.environ['TOGETHER_API_KEY']\n",
    "        client = Together(api_key =  together_api_key)\n",
    "        json_dict = client.chat.completions.create(**payload).model_dump()\n",
    "        json_dict['choices'][-1]['message']['role'] = json_dict['choices'][-1]['message']['role'].name.lower()\n",
    "    try:\n",
    "        output_dict = {'role': json_dict['choices'][-1]['message']['role'], 'content': json_dict['choices'][-1]['message']['content']}\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to get correct output dict. Please try again. Error: {e}\")\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e47d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_with_context(prompt: str, context: list,  role: str = 'user', **kwargs):\n",
    "    \"\"\"\n",
    "    Calls a language model with the given prompt and context to generate a response.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The input text prompt provided by the user.\n",
    "    - role (str): The role of the participant in the conversation, e.g., \"user\" or \"assistant\".\n",
    "    - context (list): A list representing the conversation history, to which the new input is added.\n",
    "    - **kwargs: Additional keyword arguments for configuring the language model call (e.g., top_k, temperature).\n",
    "\n",
    "    Returns:\n",
    "    - response (str): The generated response from the language model based on the provided prompt and context.\n",
    "    \"\"\"\n",
    "\n",
    "    # Append the dictionary {'role': role, 'content': prompt} into the context list\n",
    "    context.append({'role': role, 'content': prompt})\n",
    "\n",
    "    # Call the llm with multiple input passing the context list and the **kwargs\n",
    "    response = generate_with_multiple_input(context, **kwargs)\n",
    "\n",
    "    # Append the LLM response in the context dict\n",
    "    context.append(response) \n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7afa11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOGETHER_API_KEY'] = \"76d81fd6490bf6aa4277b46347bf1af6b951e468bedd5eef3abc37b851d75b31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a8dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_outfit_or_supplement(query):\n",
    "    prompt = f\"\"\"\n",
    "Determine the category of the following query as either \"nutritional\" or \"outfit\" related.\n",
    "- Nutritional queries: These are related to nutrition products, such as whey protein, vitamins, supplements, dietary products, and health-related food and beverages.\n",
    "  - Outfit queries: These pertain to clothing and fashion, including items like shirts, dresses, shoes, accessories, and jewelry.\n",
    "Examples:\n",
    "\n",
    "1. Query: “Where can I buy high-protein snacks?” Expected answer: Nutritional\n",
    "2. Query: “Best shirt styles for summer 2023” Expected answer: Outfit\n",
    "3. Query: “Are there any shoes designed for running?” Expected answer: Outfit\n",
    "4. Query: “What multivitamins should I take daily?” Expected answer: Nutritional\n",
    "5. Query: “Best weight loss products that are stylish” Expected answer: Nutritional\n",
    "6. Query: “Athletic wear that boosts performance” Expected answer: Outfit \n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Instructions: Respond with “Nutritional” if the query pertains to nutritional products or “Outfit” if it pertains to clothing or fashion products.\n",
    "Answer only one single word.\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88070686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Determine the category of the following query as either \"nutritional\" or \"outfit\" related.\n",
      "- Nutritional queries: These are related to nutrition products, such as whey protein, vitamins, supplements, dietary products, and health-related food and beverages.\n",
      "  - Outfit queries: These pertain to clothing and fashion, including items like shirts, dresses, shoes, accessories, and jewelry.\n",
      "Examples:\n",
      "\n",
      "1. Query: “Where can I buy high-protein snacks?” Expected answer: Nutritional\n",
      "2. Query: “Best shirt styles for summer 2023” Expected answer: Outfit\n",
      "3. Query: “Are there any shoes designed for running?” Expected answer: Outfit\n",
      "4. Query: “What multivitamins should I take daily?” Expected answer: Nutritional\n",
      "5. Query: “Best weight loss products that are stylish” Expected answer: Nutritional\n",
      "6. Query: “Athletic wear that boosts performance” Expected answer: Outfit \n",
      "\n",
      "Query: Give me the available vitamins supplement you have in your catalogue.\n",
      "\n",
      "Instructions: Respond with “Nutritional” if the query pertains to nutritional products or “Outfit” if it pertains to clothing or fashion products.\n",
      "Answer only one single word.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me the available vitamins supplement you have in your catalogue.\"\n",
    "test = check_if_outfit_or_supplement(query)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b9c24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': 'Nutritional'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing a simple query\n",
    "query = \"Give me the available vitamins supplement you have in your catalogue.\"\n",
    "generate_with_single_input(check_if_outfit_or_supplement(query), max_tokens = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "031d2317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Where can I buy whey protein?\n",
      "Result: Nutritional\n",
      "Expected: \u001b[92mNutritional\u001b[0m\n",
      "\n",
      "Query: Recommended vitamins for winter\n",
      "Result: Nutritional\n",
      "Expected: \u001b[92mNutritional\u001b[0m\n",
      "\n",
      "Query: Latest fashion for women's dresses\n",
      "Result: Outfit\n",
      "Expected: \u001b[92mOutfit\u001b[0m\n",
      "\n",
      "Query: Comfortable sneakers for daily use\n",
      "Result: Outfit\n",
      "Expected: \u001b[92mOutfit\u001b[0m\n",
      "\n",
      "Query: Best energy bars for athletes\n",
      "Result: Nutritional\n",
      "Expected: \u001b[92mNutritional\u001b[0m\n",
      "\n",
      "Query: Trendy accessories for men\n",
      "Result: Outfit\n",
      "Expected: \u001b[92mOutfit\u001b[0m\n",
      "\n",
      "Query: Low-carb diet food options\n",
      "Result: Nutritional\n",
      "Expected: \u001b[92mNutritional\u001b[0m\n",
      "\n",
      "Query: What supplements help with muscle recovery?\n",
      "Result: Nutritional\n",
      "Expected: \u001b[92mNutritional\u001b[0m\n",
      "\n",
      "Query: Casual wear that supports healthy living\n",
      "Result: Outfit\n",
      "Expected: \u001b[92mOutfit\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ASCII color codes\n",
    "GREEN = '\\033[92m'\n",
    "RED = '\\033[91m'\n",
    "RESET = '\\033[0m'\n",
    "\n",
    "queries = [\n",
    "    {\"query\": \"Where can I buy whey protein?\", \"label\": \"Nutritional\"},\n",
    "    {\"query\": \"Recommended vitamins for winter\", \"label\": \"Nutritional\"},\n",
    "    {\"query\": \"Latest fashion for women's dresses\", \"label\": \"Outfit\"},\n",
    "    {\"query\": \"Comfortable sneakers for daily use\", \"label\": \"Outfit\"},\n",
    "    {\"query\": \"Best energy bars for athletes\", \"label\": \"Nutritional\"},\n",
    "    {\"query\": \"Trendy accessories for men\", \"label\": \"Outfit\"},\n",
    "    {\"query\": \"Low-carb diet food options\", \"label\": \"Nutritional\"},\n",
    "    {\"query\": \"What supplements help with muscle recovery?\", \"label\": \"Nutritional\"},\n",
    "    {\"query\": \"Casual wear that supports healthy living\", \"label\": \"Outfit\"}\n",
    "]\n",
    "\n",
    "for item in queries:\n",
    "    query = item[\"query\"]\n",
    "    prompt = check_if_outfit_or_supplement(query)\n",
    "    expected_label = item[\"label\"]\n",
    "    response = generate_with_single_input(prompt, max_tokens = 2)\n",
    "    result = response['content']\n",
    "    \n",
    "    # Determine color based on comparison\n",
    "    if result == expected_label:\n",
    "        color = GREEN\n",
    "    else:\n",
    "        color = RED\n",
    "\n",
    "    print(f\"Query: {query}\\nResult: {result}\\nExpected: {color}{expected_label}{RESET}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42423f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_if_technical_or_creative(query):\n",
    "    \"\"\"\n",
    "    Determines whether a given query is creative or technical in nature.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        str: A label indicating the query type, either 'creative' or 'technical'.\n",
    "\n",
    "    This function constructs a prompt to classify a query based on its content. \n",
    "    Creative queries typically involve requests to generate original content, whereas \n",
    "    technical queries relate to documentation or technical information, such as procedures.\n",
    "    By leveraging an LLM, it identifies the query type and returns an appropriate label.\n",
    "    \"\"\"\n",
    "    \n",
    "    PROMPT = f\"\"\"Decide if the following query is a creative query or a technical query.\n",
    "    Creative queries ask you to create content, while technical queries are related to documentation or technical requests, like information about procedures.\n",
    "    Answer only 'creative' or 'technical'.\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    "    result = generate_with_single_input(PROMPT)\n",
    "    label = result['content']\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "228dad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Pi-hole?, label: technical\n",
      "Query: Suggest to me three places to visit in South America, label: Creative\n"
     ]
    }
   ],
   "source": [
    "queries = [\"What is Pi-hole?\", \n",
    "           \"Suggest to me three places to visit in South America\"]\n",
    "for query in queries:\n",
    "    label =decide_if_technical_or_creative(query)\n",
    "    print(f\"Query: {query}, label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a16396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query):\n",
    "    \"\"\"\n",
    "    Processes a query and generates an appropriate response by categorizing the query\n",
    "    as either 'technical' or 'creative', and modifies behavior based on this categorization.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to be answered.\n",
    "\n",
    "    Returns:\n",
    "        str: A generated response from the LLM tailored to the nature of the query.\n",
    "\n",
    "    This function first determines the nature of the query using the `decide_if_technical_or_creative` function. \n",
    "    If the query is classified as 'technical', it sets parameters suitable for precise and low-variability responses. \n",
    "    If the query is 'creative', it applies parameters allowing for more variability and creativity. \n",
    "    If the classification is inconclusive, it uses neutral parameters. \n",
    "    It then generates a response using these parameters and returns the content.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine whether the query is 'technical' or 'creative'\n",
    "    label = decide_if_technical_or_creative(query).lower()\n",
    "\n",
    "    # Set parameters for technical queries (precise, low randomness)\n",
    "    if label == 'technical':\n",
    "        kwargs = generate_params_dict(query, temperature=0, top_p=0.1)\n",
    "    \n",
    "    # Set parameters for creative queries (variable, high randomness)\n",
    "    elif label == 'creative':\n",
    "        kwargs = generate_params_dict(query, temperature=1.1, top_p=0.4)\n",
    "\n",
    "    # Use default parameters if the query type is inconclusive\n",
    "    else:\n",
    "        kwargs = generate_params_dict(query, temperature=0.5, top_p=0.5)\n",
    "    \n",
    "    # Generate a response based on the query type and parameters\n",
    "    response = generate_with_single_input(**kwargs)\n",
    "    \n",
    "    # Extract and return the content from the response\n",
    "    result = response['content']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0b48c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Pi-hole?\n",
      "Answer: Pi-hole is a free, open-source, and self-contained ad-blocking DNS server that can be used to block advertisements on any network. It's a simple, yet powerful solution for blocking ads, tracking scripts, and other online threats.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1. Pi-hole acts as a DNS (Domain Name System) server, which translates domain names into IP addresses that computers can understand.\n",
      "2. When a device on the network requests a website, Pi-hole intercepts the request and checks the domain name against its database of blocked ads and trackers.\n",
      "3. If the domain name is found in the blocklist, Pi-hole returns a fake IP address that directs the user to a non-existent website, effectively blocking the ad.\n",
      "4. Pi-hole can be configured to block ads on specific websites, domains, or even entire networks.\n",
      "\n",
      "Pi-hole is often used in home networks, small businesses, and organizations to:\n",
      "\n",
      "* Block ads and improve browsing speed\n",
      "* Reduce online tracking and data collection\n",
      "* Improve online security by blocking malicious websites\n",
      "* Enhance user experience by removing unwanted content\n",
      "\n",
      "Pi-hole is available as a software package that can be installed on a Raspberry Pi, a small, affordable single-board computer. It's also available as a cloud-based service, making it accessible to users without a Raspberry Pi.\n",
      "\n",
      "Some of the key benefits of Pi-hole include:\n",
      "\n",
      "* Easy to set up and use\n",
      "* Highly customizable\n",
      "* Open-source and community-driven\n",
      "* Free and open-source\n",
      "* Scalable and reliable\n",
      "\n",
      "Overall, Pi-hole is a powerful tool for anyone looking to improve their online experience by blocking ads and online threats.\n",
      "\n",
      "#######\n",
      "\n",
      "Query: Suggest to me three places to visit in South America\n",
      "Answer: South America is a vast and diverse continent, offering countless exciting destinations to explore. Here are three places to visit in South America:\n",
      "\n",
      "1. **Machu Picchu, Peru**: This ancient Inca city is one of the most famous and mysterious sites in South America. Perched on a mountain ridge over 7,000 feet above sea level, Machu Picchu is a breathtaking example of Inca engineering and architecture. The site is steeped in history and offers stunning views of the surrounding Andean mountains.\n",
      "\n",
      "2. **Iguazu Falls, Argentina/Brazil**: Located on the border of Argentina and Brazil, Iguazu Falls is one of the world's most spectacular waterfalls. The falls consist of over 275 individual cascades, spanning almost 2 miles in length. Visitors can hike, take a boat tour, or simply stand in awe of the sheer power and beauty of the falls.\n",
      "\n",
      "3. **Rio de Janeiro, Brazil**: Known for its vibrant culture, stunning beaches, and iconic landmarks like Christ the Redeemer and Sugarloaf Mountain, Rio de Janeiro is a must-visit destination in South America. The city's Carnival celebrations are legendary, and its beaches, such as Copacabana and Ipanema, are among the most beautiful in the world.\n",
      "\n",
      "These are just a few of the many incredible destinations in South America. Each place offers a unique cultural, historical, and natural experience that will leave you with lifelong memories.\n",
      "\n",
      "#######\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\"What is Pi-hole?\", \n",
    "           \"Suggest to me three places to visit in South America\"]\n",
    "for query in queries:\n",
    "    result = answer_query(query)\n",
    "    print(f\"Query: {query}\\nAnswer: {result}\\n\\n#######\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b5d9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_system_call(command):\n",
    "    PROMPT = f\"\"\"\n",
    "You are an assistant program that converts natural language commands into structured JSON for controlling smart home devices. The JSON should conform to a specific format describing the device, action, and parameters. Here's how you can do it:\n",
    "\n",
    "**Available Devices and Actions:**\n",
    "\n",
    "1. **Light**\n",
    "   - Actions: \"turn on\", \"turn off\"\n",
    "   - Parameters: color, intensity (percentage)\n",
    "\n",
    "2. **Automatic Lock**\n",
    "   - Actions: \"lock\", \"unlock\"\n",
    "   - Parameters: None\n",
    "\n",
    "3. **Sound System (Speaker)**\n",
    "   - Actions: \"play\", \"pause\", \"stop\", \"set volume\"\n",
    "   - Parameters: volume (integer), track (string), playlist_style (string)\n",
    "\n",
    "4. **TV**\n",
    "   - Actions: \"turn on\", \"turn off\", \"change channel\", \"adjust volume\"\n",
    "   - Parameters: channel (string), volume (integer)\n",
    "\n",
    "5. **Air Conditioner**\n",
    "   - Actions: \"turn on\", \"turn off\", \"set temperature\", \"adjust fan speed\"\n",
    "   - Parameters: temperature (integer), fan_speed (low/medium/high)\n",
    "\n",
    "**Rooms and Devices:**\n",
    "- **Office**\n",
    "  - Lights: \"office_light_1\" (ID: 123), \"office_light_2\" (ID: 321)\n",
    "  - Automatic Lock: \"office_door_lock\" (ID: 111)\n",
    "\n",
    "- **Living Room**\n",
    "  - Light: \"living_room_light\" (ID: 222)\n",
    "  - Speaker: \"living_room_speaker\" (ID: 223)\n",
    "  - Air Conditioner: \"living_room_airconditioner\" (ID: 556)\n",
    "\n",
    "- **Kitchen**\n",
    "  - Light: \"kitchen_light\" (ID: 333)\n",
    "\n",
    "- **Bedroom**\n",
    "  - Light: \"bedroom_light\" (ID: 444)\n",
    "  - TV: \"bedroom_tv\" (ID: 445)\n",
    "\n",
    "- **Bathroom**\n",
    "  - Light: \"bathroom_light\" (ID: 555)\n",
    "\n",
    "**Task:**\n",
    "Convert the following natural language command into the structured JSON format based on the available devices:\n",
    "\n",
    "**Input Examples:**\n",
    "\n",
    "1. \"Turn on the office light with ID 123 with blue color and 50% intensity.\"\n",
    "   - JSON:\n",
    "     [\n",
    "     {{\n",
    "       \"room\": \"office\",\n",
    "       \"object_id\": \"123\",\n",
    "       \"object_name\": \"office_light_1\",\n",
    "       \"action\": \"turn on\",\n",
    "       \"parameters\": {{\"color\": \"blue\", \"intensity\": \"50%\"}}\n",
    "     }}\n",
    "     ]\n",
    "\n",
    "2. \"Lock the office door.\"\n",
    "   - JSON:\n",
    "   [\n",
    "     {{\n",
    "       \"room\": \"office\",\n",
    "       \"object_id\": \"111\",\n",
    "       \"object_name\": \"office_door_lock\",\n",
    "       \"action\": \"lock\",\n",
    "       \"parameters\": {{}}\n",
    "     }}\n",
    "    ]\n",
    "\n",
    "2. \"Make my living room a cheerful place\"\n",
    "   - JSON:\n",
    "   [\n",
    "     {{\n",
    "       \"room\": \"living_room\",\n",
    "       \"object_id\": \"222\",\n",
    "       \"object_name\": \"living_room_light\",\n",
    "       \"action\": \"turn on\",\n",
    "       \"parameters\": {{'intensity': '80%', 'color':'yellow'}}\n",
    "     }},\n",
    "     {{\n",
    "       \"room\": \"living_room\",\n",
    "       \"object_id\": \"223\",\n",
    "       \"object_name\": \"living_room_speaker\",\n",
    "       \"action\": \"turn on\",\n",
    "       \"parameters\": {{'volume': '100', 'playlist_style':'party'}}\n",
    "     }},\n",
    "     \n",
    "   ]\n",
    "\n",
    "**Note:**\n",
    "- Ensure that each JSON object correctly maps the natural command to the appropriate device and action using the listed device ID.\n",
    "- Use the object ID to differentiate between devices when the room contains multiple similar items.\n",
    "- You can add more than one parameter in the parameters dictionary.\n",
    "\n",
    "Using this information, translate the following command into JSON: \"{command}\". Output a list with all the necessary JSONs. \n",
    "Always output a list even if there is only one command to be applied, do not output anything else but the desired structure.\n",
    "\"\"\"\n",
    "    kwargs = generate_params_dict(PROMPT, temperature=0.4, top_p=0.1)\n",
    "    result = generate_with_single_input(**kwargs)\n",
    "    return result['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d3a5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"room\": \"living_room\",\n",
      "    \"object_id\": \"223\",\n",
      "    \"object_name\": \"living_room_speaker\",\n",
      "    \"action\": \"turn on\",\n",
      "    \"parameters\": {\"volume\": \"100\", \"playlist_style\": \"chill\"}\n",
      "  },\n",
      "  {\n",
      "    \"room\": \"living_room\",\n",
      "    \"object_id\": \"223\",\n",
      "    \"object_name\": \"living_room_speaker\",\n",
      "    \"action\": \"set volume\",\n",
      "    \"parameters\": {\"volume\": \"100\"}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(generate_system_call(\"Play a chill playlist very loud\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37ca9e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"room\": \"living_room\",\n",
      "    \"object_id\": \"222\",\n",
      "    \"object_name\": \"living_room_light\",\n",
      "    \"action\": \"turn on\",\n",
      "    \"parameters\": {\"intensity\": \"100%\", \"color\": \"warm white\"}\n",
      "  },\n",
      "  {\n",
      "    \"room\": \"living_room\",\n",
      "    \"object_id\": \"223\",\n",
      "    \"object_name\": \"living_room_speaker\",\n",
      "    \"action\": \"turn on\",\n",
      "    \"parameters\": {\"volume\": \"100\", \"playlist_style\": \"relaxing\"}\n",
      "  },\n",
      "  {\n",
      "    \"room\": \"living_room\",\n",
      "    \"object_id\": \"556\",\n",
      "    \"object_name\": \"living_room_airconditioner\",\n",
      "    \"action\": \"turn on\",\n",
      "    \"parameters\": {\"temperature\": \"22\", \"fan_speed\": \"low\"}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(generate_system_call(\"I'm tired today, please make my living room a very cozy ambient, it is really cold today too.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17f750f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, validator, conint, Field\n",
    "from typing import Literal, Union, Optional, List\n",
    "import json\n",
    "\n",
    "# Define the schema for the output\n",
    "class VoiceNote(BaseModel):\n",
    "    title: str = Field(description=\"A title for the voice note\")\n",
    "    summary: str = Field(description=\"A short one sentence summary of the voice note.\")\n",
    "    actionItems: list[str] = Field(\n",
    "        description=\"A list of action items from the voice note\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e1b01fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Morning Routine\",\n",
      "  \"summary\": \"Preparing breakfast at 7:00 AM, checking emails.\",\n",
      "  \"actionItems\": [\n",
      "    \"> Eat scrambled eggs and toast\",\n",
      "    \"> Drink a cup of coffee\",\n",
      "    \"> Check emails\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "transcript = (\n",
    "        \"Good morning! It's 7:00 AM, and I'm just waking up. Today is going to be a busy day, \"\n",
    "        \"so let's get started. First, I need to make a quick breakfast. I think I'll have some \"\n",
    "        \"scrambled eggs and toast with a cup of coffee. While I'm cooking, I'll also check my \"\n",
    "        \"emails to see if there's anything urgent.\"\n",
    "    )\n",
    "\n",
    "\n",
    "messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"The following is a voice message transcript. Only answer in JSON.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcript,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"schema\": VoiceNote.model_json_schema(),\n",
    "        }\n",
    "\n",
    "result = generate_with_multiple_input(messages, response_format = response_format)\n",
    "result_json = json.loads(result['content'])\n",
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcddc3de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
